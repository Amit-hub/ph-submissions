{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "First, we import the library. Then, we grab the API tokens from our `keys.py` file (not in Git!).\n",
    "\n",
    "Before running this code, check that you are in the `ml-mhl` environment.\n",
    "\n",
    "```bash\n",
    "conda env list\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import internetarchive as ia\n",
    "from keys import ia_keys\n",
    "import os\n",
    "import requests\n",
    "import sys\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\stephen-krewson/.ia'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ia.configure(ia_keys['username'], ia_keys['password'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UF00003119', 'talespeterparle00goodgoog']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample search\n",
    "query = \"peter parley date:[1825 TO 1830] mediatype:texts\"\n",
    "vol_ids = [result['identifier'] for result in ia.search_items(query)]\n",
    "vol_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ia_download(item_id, out_dir=None):\n",
    "    \"\"\"\n",
    "    :param item_id: unique Internet Archive volume identifier\n",
    "    :param out_dir: destination for images; if None, no download\n",
    "    \n",
    "    Note: if supplied, out_dir must be an existing directory and\n",
    "    the caller must have write permissions in that directory\n",
    "    \n",
    "    :rtype list of pages with one or more blockType=Picture in OCR data\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"[{}] Starting processing\".format(item_id))\n",
    "    \n",
    "    # See common formats for book with:\n",
    "    # ia metadata formats peterparleysmet00goodgoog\n",
    "    returned_files = list(ia.get_files(item_id, formats=[\"Abbyy GZ\"]))\n",
    "    \n",
    "    # make sure something got returned\n",
    "    if len(returned_files) > 0:\n",
    "        abbyy_file = returned_files[0].name\n",
    "    else:\n",
    "        print(\"[{}] Could not get Abbyy file\".format(item_id))\n",
    "        return None\n",
    "    \n",
    "    # download the abbyy file to CWD\n",
    "    ia.download(item_id, formats=[\"Abbyy GZ\"], ignore_existing=True, destdir=os.getcwd(), no_directory=True)\n",
    "    \n",
    "    # collect the pages with at least one picture block\n",
    "    img_pages = []\n",
    "    \n",
    "    with gzip.open(abbyy_file) as fp:\n",
    "        tree = ET.parse(fp)\n",
    "        document = tree.getroot()\n",
    "        for i, page in enumerate(document):\n",
    "            for block in page:\n",
    "                try:\n",
    "                    if block.attrib['blockType'] == 'Picture':\n",
    "                        img_pages.append(i)\n",
    "                        break\n",
    "                except KeyError:\n",
    "                    continue\n",
    "    \n",
    "    # 0 is not a valid page for making GET requests to IA, yet sometimes\n",
    "    # it's in the zipped Abbyy file\n",
    "    img_pages = [page for page in img_pages if page > 0]\n",
    "    \n",
    "    # track for download progress report\n",
    "    total_pages = len(img_pages)\n",
    "\n",
    "    # OCR files are huge, so just delete once we have pagelist\n",
    "    os.remove(abbyy_file)\n",
    "    \n",
    "    # if out_dir is not None, then also download page images\n",
    "    if out_dir:\n",
    "        \n",
    "        # return if folder already exists (reasonable inference that volume already processed)\n",
    "        if os.path.isdir(out_dir):\n",
    "            print(\"[{}] Directory already exists.\".format(item_id))\n",
    "            return img_pages\n",
    "\n",
    "        # otherwise, create folder to put the images\n",
    "        print(\"[{}] Making directory\".format(out_dir))\n",
    "        os.makedirs(out_dir)\n",
    "        \n",
    "        # See Michael Karpeles email! saves tedious JP2 conversion\n",
    "        # now we want the urls (PNG is also an option)\n",
    "        urls = [\"https://iiif.archivelab.org/iiif/{}${}/full/full/0/default.jpg\".format(item_id, page) for page in img_pages]\n",
    "        \n",
    "        # no direct page download through API, DIY\n",
    "        for i, page, url in zip(range(1,total_pages), img_pages, urls):\n",
    "            rsp = requests.get(url, allow_redirects=True)\n",
    "            if rsp.status_code == 200:\n",
    "                print(\"[{}] Downloading page {} ({}/{})\".format(item_id, page, i+1, total_pages))\n",
    "                with open(os.path.join(out_dir, str(page) + \".jpg\"), \"wb\") as fp:\n",
    "                    fp.write(rsp.content)\n",
    "    \n",
    "    # return this just for kicks\n",
    "    return img_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UF00003119] Starting processing\n",
      "[UF00003119] Could not get Abbyy file\n",
      "[talespeterparle00goodgoog] Starting processing\n",
      "talespeterparle00goodgoog: d - success\n",
      "[talespeterparle00goodgoog] Making directory\n",
      "[talespeterparle00goodgoog] Downloading page 1 (2/43)\n",
      "[talespeterparle00goodgoog] Downloading page 2 (3/43)\n",
      "[talespeterparle00goodgoog] Downloading page 7 (4/43)\n",
      "[talespeterparle00goodgoog] Downloading page 8 (5/43)\n",
      "[talespeterparle00goodgoog] Downloading page 12 (6/43)\n",
      "[talespeterparle00goodgoog] Downloading page 14 (7/43)\n",
      "[talespeterparle00goodgoog] Downloading page 16 (8/43)\n",
      "[talespeterparle00goodgoog] Downloading page 17 (9/43)\n",
      "[talespeterparle00goodgoog] Downloading page 18 (10/43)\n",
      "[talespeterparle00goodgoog] Downloading page 19 (11/43)\n",
      "[talespeterparle00goodgoog] Downloading page 22 (12/43)\n",
      "[talespeterparle00goodgoog] Downloading page 27 (13/43)\n",
      "[talespeterparle00goodgoog] Downloading page 33 (14/43)\n",
      "[talespeterparle00goodgoog] Downloading page 35 (15/43)\n",
      "[talespeterparle00goodgoog] Downloading page 37 (16/43)\n",
      "[talespeterparle00goodgoog] Downloading page 38 (17/43)\n",
      "[talespeterparle00goodgoog] Downloading page 44 (18/43)\n",
      "[talespeterparle00goodgoog] Downloading page 45 (19/43)\n",
      "[talespeterparle00goodgoog] Downloading page 46 (20/43)\n",
      "[talespeterparle00goodgoog] Downloading page 47 (21/43)\n",
      "[talespeterparle00goodgoog] Downloading page 48 (22/43)\n",
      "[talespeterparle00goodgoog] Downloading page 49 (23/43)\n",
      "[talespeterparle00goodgoog] Downloading page 52 (24/43)\n",
      "[talespeterparle00goodgoog] Downloading page 55 (25/43)\n",
      "[talespeterparle00goodgoog] Downloading page 57 (26/43)\n",
      "[talespeterparle00goodgoog] Downloading page 58 (27/43)\n",
      "[talespeterparle00goodgoog] Downloading page 59 (28/43)\n",
      "[talespeterparle00goodgoog] Downloading page 60 (29/43)\n",
      "[talespeterparle00goodgoog] Downloading page 61 (30/43)\n",
      "[talespeterparle00goodgoog] Downloading page 65 (31/43)\n",
      "[talespeterparle00goodgoog] Downloading page 68 (32/43)\n",
      "[talespeterparle00goodgoog] Downloading page 69 (33/43)\n",
      "[talespeterparle00goodgoog] Downloading page 73 (34/43)\n",
      "[talespeterparle00goodgoog] Downloading page 74 (35/43)\n",
      "[talespeterparle00goodgoog] Downloading page 76 (36/43)\n",
      "[talespeterparle00goodgoog] Downloading page 80 (37/43)\n",
      "[talespeterparle00goodgoog] Downloading page 86 (38/43)\n",
      "[talespeterparle00goodgoog] Downloading page 87 (39/43)\n",
      "[talespeterparle00goodgoog] Downloading page 88 (40/43)\n",
      "[talespeterparle00goodgoog] Downloading page 103 (41/43)\n",
      "[talespeterparle00goodgoog] Downloading page 128 (42/43)\n",
      "[talespeterparle00goodgoog] Downloading page 129 (43/43)\n"
     ]
    }
   ],
   "source": [
    "for item_id in vol_ids:\n",
    "    img_pages = ia_download(item_id, out_dir=item_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
