{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "First, we import the library. Then, we grab the API tokens from our `keys.py` file (not in Git!).\n",
    "\n",
    "Before running this code, check that you are in the `ml-mhl` environment.\n",
    "\n",
    "```bash\n",
    "conda env list\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import internetarchive as ia\n",
    "from keys import ia_keys\n",
    "import os\n",
    "import requests\n",
    "import sys\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\stephen-krewson/.ia'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ia.configure(ia_keys['username'], ia_keys['password'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UF00003119', 'talespeterparle00goodgoog']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample search\n",
    "query = \"peter parley date:[1825 TO 1830] mediatype:texts\"\n",
    "vol_ids = [result['identifier'] for result in ia.search_items(query)]\n",
    "vol_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ia_download(item_id, out_dir=None):\n",
    "    \"\"\"\n",
    "    :param item_id: unique Internet Archive volume identifier\n",
    "    :param out_dir: destination for images; if None, no download\n",
    "    \n",
    "    Note: if supplied, out_dir must be an existing directory and\n",
    "    the caller must have write permissions in that directory\n",
    "    \n",
    "    :rtype list of pages with one or more blockType=Picture in OCR data\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"[{}] Starting processing\".format(item_id))\n",
    "    \n",
    "    # See common formats for book with:\n",
    "    # ia metadata formats peterparleysmet00goodgoog\n",
    "    returned_files = list(ia.get_files(item_id, formats=[\"Abbyy GZ\"]))\n",
    "    \n",
    "    # make sure something got returned\n",
    "    if len(returned_files) > 0:\n",
    "        abbyy_file = returned_files[0].name\n",
    "    else:\n",
    "        print(\"[{}] Could not get Abbyy file\".format(item_id))\n",
    "        return None\n",
    "    \n",
    "    # download the abbyy file to CWD\n",
    "    ia.download(item_id, formats=[\"Abbyy GZ\"], ignore_existing=True, destdir=os.getcwd(), no_directory=True)\n",
    "    \n",
    "    # collect the pages with at least one picture block\n",
    "    img_pages = []\n",
    "    \n",
    "    with gzip.open(abbyy_file) as fp:\n",
    "        tree = ET.parse(fp)\n",
    "        document = tree.getroot()\n",
    "        for i, page in enumerate(document):\n",
    "            for block in page:\n",
    "                try:\n",
    "                    if block.attrib['blockType'] == 'Picture':\n",
    "                        img_pages.append(i)\n",
    "                        break\n",
    "                except KeyError:\n",
    "                    continue\n",
    "    \n",
    "    # 0 is not a valid page for making GET requests to IA, yet sometimes\n",
    "    # it's in the zipped Abbyy file\n",
    "    img_pages = [page for page in img_pages if page > 0]\n",
    "    \n",
    "    # track for download progress report\n",
    "    total_pages = len(img_pages)\n",
    "\n",
    "    # OCR files are huge, so just delete once we have pagelist\n",
    "    os.remove(abbyy_file)\n",
    "    \n",
    "    # if out_dir is not None, then also download page images\n",
    "    if out_dir:\n",
    "        \n",
    "        # return if folder already exists (reasonable inference that volume already processed)\n",
    "        if os.path.isdir(out_dir):\n",
    "            print(\"[{}] Directory already exists.\".format(item_id))\n",
    "            return img_pages\n",
    "\n",
    "        # otherwise, create folder to put the images\n",
    "        print(\"[{}] Making directory {}\".format(item_id, out_dir))\n",
    "        os.makedirs(out_dir)\n",
    "        \n",
    "        # See Michael Karpeles email! saves tedious JP2 conversion\n",
    "        # now we want the urls (PNG is also an option)\n",
    "        # https://iiif.archivelab.org/iiif/documentation\n",
    "        urls = [\"https://iiif.archivelab.org/iiif/{}${}/full/full/0/default.jpg\".format(item_id, page) for page in img_pages]\n",
    "        \n",
    "        # no direct page download through API, DIY\n",
    "        for i, page, url in zip(range(1,total_pages), img_pages, urls):\n",
    "            rsp = requests.get(url, allow_redirects=True)\n",
    "            if rsp.status_code == 200:\n",
    "                print(\"[{}] Downloading page {} ({}/{})\".format(item_id, page, i+1, total_pages))\n",
    "                with open(os.path.join(out_dir, str(page) + \".jpg\"), \"wb\") as fp:\n",
    "                    fp.write(rsp.content)\n",
    "    \n",
    "    # return this just for kicks\n",
    "    return img_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UF00003119] Starting processing\n",
      "[UF00003119] Could not get Abbyy file\n",
      "[talespeterparle00goodgoog] Starting processing\n",
      "talespeterparle00goodgoog: d - success\n",
      "[volumes\\ia\\talespeterparle00goodgoog] Making directory\n",
      "[talespeterparle00goodgoog] Downloading page 1 (2/43)\n",
      "[talespeterparle00goodgoog] Downloading page 2 (3/43)\n",
      "[talespeterparle00goodgoog] Downloading page 7 (4/43)\n",
      "[talespeterparle00goodgoog] Downloading page 8 (5/43)\n",
      "[talespeterparle00goodgoog] Downloading page 12 (6/43)\n",
      "[talespeterparle00goodgoog] Downloading page 14 (7/43)\n",
      "[talespeterparle00goodgoog] Downloading page 16 (8/43)\n",
      "[talespeterparle00goodgoog] Downloading page 17 (9/43)\n",
      "[talespeterparle00goodgoog] Downloading page 18 (10/43)\n",
      "[talespeterparle00goodgoog] Downloading page 19 (11/43)\n",
      "[talespeterparle00goodgoog] Downloading page 22 (12/43)\n",
      "[talespeterparle00goodgoog] Downloading page 27 (13/43)\n",
      "[talespeterparle00goodgoog] Downloading page 33 (14/43)\n",
      "[talespeterparle00goodgoog] Downloading page 35 (15/43)\n",
      "[talespeterparle00goodgoog] Downloading page 37 (16/43)\n",
      "[talespeterparle00goodgoog] Downloading page 38 (17/43)\n",
      "[talespeterparle00goodgoog] Downloading page 44 (18/43)\n",
      "[talespeterparle00goodgoog] Downloading page 45 (19/43)\n",
      "[talespeterparle00goodgoog] Downloading page 46 (20/43)\n",
      "[talespeterparle00goodgoog] Downloading page 47 (21/43)\n",
      "[talespeterparle00goodgoog] Downloading page 48 (22/43)\n",
      "[talespeterparle00goodgoog] Downloading page 49 (23/43)\n",
      "[talespeterparle00goodgoog] Downloading page 52 (24/43)\n",
      "[talespeterparle00goodgoog] Downloading page 55 (25/43)\n",
      "[talespeterparle00goodgoog] Downloading page 57 (26/43)\n",
      "[talespeterparle00goodgoog] Downloading page 58 (27/43)\n",
      "[talespeterparle00goodgoog] Downloading page 59 (28/43)\n",
      "[talespeterparle00goodgoog] Downloading page 60 (29/43)\n",
      "[talespeterparle00goodgoog] Downloading page 61 (30/43)\n",
      "[talespeterparle00goodgoog] Downloading page 65 (31/43)\n",
      "[talespeterparle00goodgoog] Downloading page 68 (32/43)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-dc18135c4b69>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvol_ids\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m# N.B. stash this in volumes/ia so git will ignore it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mimg_pages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mia_download\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"volumes\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ia\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-812058bee9ec>\u001b[0m in \u001b[0;36mia_download\u001b[1;34m(item_id, out_dir)\u001b[0m\n\u001b[0;32m     74\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"[{}] Downloading page {} ({}/{})\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_pages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".jpg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m                     \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrsp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;31m# return this just for kicks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for item_id in vol_ids:\n",
    "    # N.B. stash this in volumes/ia so git will ignore it\n",
    "    img_pages = ia_download(item_id, out_dir=os.path.join(\"items\", \"internetarchive\", item_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
